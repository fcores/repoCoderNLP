{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DATASET SELECCIONADO: Yellow_Submarine.csv\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>cap-shape</th>\n",
       "      <th>cap-surface</th>\n",
       "      <th>cap-color</th>\n",
       "      <th>bruises</th>\n",
       "      <th>odor</th>\n",
       "      <th>gill-attachment</th>\n",
       "      <th>gill-spacing</th>\n",
       "      <th>gill-size</th>\n",
       "      <th>gill-color</th>\n",
       "      <th>...</th>\n",
       "      <th>stalk-surface-below-ring</th>\n",
       "      <th>stalk-color-above-ring</th>\n",
       "      <th>stalk-color-below-ring</th>\n",
       "      <th>veil-type</th>\n",
       "      <th>veil-color</th>\n",
       "      <th>ring-number</th>\n",
       "      <th>ring-type</th>\n",
       "      <th>spore-print-color</th>\n",
       "      <th>population</th>\n",
       "      <th>habitat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>...</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "      <td>8124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>2</td>\n",
       "      <td>9</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>12</td>\n",
       "      <td>...</td>\n",
       "      <td>4</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>6</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>edible</td>\n",
       "      <td>convex</td>\n",
       "      <td>scaly</td>\n",
       "      <td>brown</td>\n",
       "      <td>no</td>\n",
       "      <td>none</td>\n",
       "      <td>free</td>\n",
       "      <td>close</td>\n",
       "      <td>broad</td>\n",
       "      <td>buff</td>\n",
       "      <td>...</td>\n",
       "      <td>smooth</td>\n",
       "      <td>white</td>\n",
       "      <td>white</td>\n",
       "      <td>partial</td>\n",
       "      <td>white</td>\n",
       "      <td>one</td>\n",
       "      <td>pendant</td>\n",
       "      <td>white</td>\n",
       "      <td>several</td>\n",
       "      <td>woods</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>4208</td>\n",
       "      <td>3656</td>\n",
       "      <td>3244</td>\n",
       "      <td>2284</td>\n",
       "      <td>4748</td>\n",
       "      <td>3528</td>\n",
       "      <td>7914</td>\n",
       "      <td>6812</td>\n",
       "      <td>5612</td>\n",
       "      <td>1728</td>\n",
       "      <td>...</td>\n",
       "      <td>4936</td>\n",
       "      <td>4464</td>\n",
       "      <td>4384</td>\n",
       "      <td>8124</td>\n",
       "      <td>7924</td>\n",
       "      <td>7488</td>\n",
       "      <td>3968</td>\n",
       "      <td>2388</td>\n",
       "      <td>4040</td>\n",
       "      <td>3148</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4 rows × 23 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         class cap-shape cap-surface cap-color bruises  odor gill-attachment  \\\n",
       "count     8124      8124        8124      8124    8124  8124            8124   \n",
       "unique       2         6           4        10       2     9               2   \n",
       "top     edible    convex       scaly     brown      no  none            free   \n",
       "freq      4208      3656        3244      2284    4748  3528            7914   \n",
       "\n",
       "       gill-spacing gill-size gill-color  ... stalk-surface-below-ring  \\\n",
       "count          8124      8124       8124  ...                     8124   \n",
       "unique            2         2         12  ...                        4   \n",
       "top           close     broad       buff  ...                   smooth   \n",
       "freq           6812      5612       1728  ...                     4936   \n",
       "\n",
       "       stalk-color-above-ring stalk-color-below-ring veil-type veil-color  \\\n",
       "count                    8124                   8124      8124       8124   \n",
       "unique                      9                      9         1          4   \n",
       "top                     white                  white   partial      white   \n",
       "freq                     4464                   4384      8124       7924   \n",
       "\n",
       "       ring-number ring-type spore-print-color population habitat  \n",
       "count         8124      8124              8124       8124    8124  \n",
       "unique           3         5                 9          6       7  \n",
       "top            one   pendant             white    several   woods  \n",
       "freq          7488      3968              2388       4040    3148  \n",
       "\n",
       "[4 rows x 23 columns]"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Importar Librerias\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "import pandas as pd\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = 'Yellow_Submarine.csv'\n",
    "dataset = pd.read_csv(file_path)\n",
    "dataset.describe()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 8124 entries, 0 to 8123\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype \n",
      "---  ------                    --------------  ----- \n",
      " 0   class                     8124 non-null   object\n",
      " 1   cap-shape                 8124 non-null   object\n",
      " 2   cap-surface               8124 non-null   object\n",
      " 3   cap-color                 8124 non-null   object\n",
      " 4   bruises                   8124 non-null   object\n",
      " 5   odor                      8124 non-null   object\n",
      " 6   gill-attachment           8124 non-null   object\n",
      " 7   gill-spacing              8124 non-null   object\n",
      " 8   gill-size                 8124 non-null   object\n",
      " 9   gill-color                8124 non-null   object\n",
      " 10  stalk-shape               8124 non-null   object\n",
      " 11  stalk-root                8124 non-null   object\n",
      " 12  stalk-surface-above-ring  8124 non-null   object\n",
      " 13  stalk-surface-below-ring  8124 non-null   object\n",
      " 14  stalk-color-above-ring    8124 non-null   object\n",
      " 15  stalk-color-below-ring    8124 non-null   object\n",
      " 16  veil-type                 8124 non-null   object\n",
      " 17  veil-color                8124 non-null   object\n",
      " 18  ring-number               8124 non-null   object\n",
      " 19  ring-type                 8124 non-null   object\n",
      " 20  spore-print-color         8124 non-null   object\n",
      " 21  population                8124 non-null   object\n",
      " 22  habitat                   8124 non-null   object\n",
      "dtypes: object(23)\n",
      "memory usage: 1.4+ MB\n"
     ]
    }
   ],
   "source": [
    "# Chequeamos que nuestro dataset no tenga valores nulos ni duplicados\n",
    "dataset.select_dtypes('object').info()\n",
    "dataset.drop_duplicates(keep = False, inplace = True)\n",
    "dataset.dropna(how='any', inplace=True)\n",
    "dataset.shape\n",
    "\n",
    "# Codificamos la variable objetivo (class) en valores numéricos\n",
    "label_encoder = LabelEncoder()\n",
    "dataset['class'] = label_encoder.fit_transform(dataset['class'])\n",
    "\n",
    "# Codificamos las en tipo categóricas\n",
    "categorical_features = dataset.drop(columns=['class']).select_dtypes('object').columns\n",
    "dataset_encoded = pd.get_dummies(dataset, columns=categorical_features, drop_first=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['odor_none', 'gill-size_narrow'], dtype='object')\n"
     ]
    }
   ],
   "source": [
    "# Seleccionamos las 10 características más importantes\n",
    "X = dataset_encoded.drop(columns=['class'])  # Característica predictora\n",
    "y = dataset_encoded['class']  # Variable objetivo\n",
    "\n",
    "# Usamos un modelo RandomForest para determinar las caracteristicas más relevantes\n",
    "model = RandomForestClassifier(\n",
    "        n_estimators=100,  # Número de árboles\n",
    "        max_depth=10,      # Profundidad máxima de los árboles\n",
    "        min_samples_split=5,  # Mínimo de muestras para dividir un nodo\n",
    "        min_samples_leaf=2,   # Mínimo de muestras en las hojas\n",
    "        random_state=42\n",
    "    )\n",
    "model.fit(X, y)\n",
    "\n",
    "# Obtenemos las 10 características más importantes\n",
    "importances = pd.Series(model.feature_importances_, index=X.columns)\n",
    "top_features = importances.nlargest(2).index\n",
    "\n",
    "\n",
    "# Crear un nuevo conjunto de datos solo con las características seleccionadas\n",
    "X_reduced = X[top_features]\n",
    "\n",
    "print(top_features)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 5. Dividimos el conjunto en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_reduced, y, test_size=0.3, random_state=42)\n",
    "\n",
    "# 6. Inicializamos los modelos\n",
    "models = {\n",
    "    'Random Forest': RandomForestClassifier(\n",
    "        n_estimators=150,  # Número de árboles\n",
    "        max_depth=10,      # Profundidad máxima de los árboles\n",
    "        min_samples_split=5,  # Mínimo de muestras para dividir un nodo\n",
    "        min_samples_leaf=2,   # Mínimo de muestras en las hojas\n",
    "        random_state=42\n",
    "    ),\n",
    "    'Logistic Regression': LogisticRegression(max_iter=500),\n",
    "    'SVM': SVC()\n",
    "    \n",
    "}\n",
    "\n",
    "# Entrenamos y evaluamos los modelos\n",
    "results = {}\n",
    "\n",
    "for model_name, model in models.items():\n",
    "    model.fit(X_train, y_train)  # Entrenar\n",
    "    y_pred = model.predict(X_test)  # Predecir\n",
    "    results[model_name] = classification_report(y_test, y_pred, output_dict=True)\n",
    "\n",
    "# Mostramos los resultados\n",
    "results_df = pd.DataFrame({\n",
    "    model_name: {\n",
    "        'Precision': report['1']['precision'],\n",
    "        'Recall': report['1']['recall'],\n",
    "        'F1-Score': report['1']['f1-score'],\n",
    "        'Accuracy': report['accuracy']\n",
    "    }\n",
    "    for model_name, report in results.items()\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5) Resultados Obtenidos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "           Random Forest  Logistic Regression       SVM\n",
      "Precision       0.812811             0.812811  0.812811\n",
      "Recall          0.966977             0.966977  0.966977\n",
      "F1-Score        0.883217             0.883217  0.883217\n",
      "Accuracy        0.876128             0.876128  0.876128\n"
     ]
    }
   ],
   "source": [
    "print(results_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\facun\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 5ms/step - accuracy: 0.9337 - loss: 0.3740 - val_accuracy: 0.9846 - val_loss: 0.0521\n",
      "Epoch 2/5\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9840 - loss: 0.0521 - val_accuracy: 0.9846 - val_loss: 0.0451\n",
      "Epoch 3/5\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - accuracy: 0.9857 - loss: 0.0426 - val_accuracy: 0.9846 - val_loss: 0.0387\n",
      "Epoch 4/5\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9867 - loss: 0.0355 - val_accuracy: 0.9871 - val_loss: 0.0338\n",
      "Epoch 5/5\n",
      "\u001b[1m204/204\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.9865 - loss: 0.0352 - val_accuracy: 0.9865 - val_loss: 0.0352\n",
      "\u001b[1m51/51\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - accuracy: 0.9887 - loss: 0.0256\n",
      "Pérdida: 0.03518444299697876, Precisión: 0.9864615201950073\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Embedding, LSTM\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Cargar el dataset\n",
    "file_path = \"Yellow_Submarine.csv\"\n",
    "data = pd.read_csv(file_path)\n",
    "\n",
    "# Generar texto combinando columnas categóricas\n",
    "data[\"text\"] = data[[\"cap-shape\", \"cap-surface\", \"cap-color\", \"odor\"]].astype(str).agg(' '.join, axis=1)\n",
    "\n",
    "# Etiquetas binarias (1 para \"poisson\", 0 para \"edible\")\n",
    "data[\"label\"] = data[\"class\"].apply(lambda x: 1 if x == \"poisson\" else 0)\n",
    "\n",
    "# Lista manual de stopwords en inglés\n",
    "stop_words = {\n",
    "    'i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours', 'yourself', 'yourselves',\n",
    "    'he', 'him', 'his', 'himself', 'she', 'her', 'hers', 'herself', 'it', 'its', 'itself', 'they', 'them', 'their',\n",
    "    'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are', 'was',\n",
    "    'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and',\n",
    "    'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between',\n",
    "    'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on',\n",
    "    'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all',\n",
    "    'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same',\n",
    "    'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now'\n",
    "}\n",
    "\n",
    "def preprocess_text(text):\n",
    "    tokens = text.lower().split()\n",
    "    filtered_tokens = [word for word in tokens if word.isalnum() and word not in stop_words]\n",
    "    return \" \".join(filtered_tokens)\n",
    "\n",
    "try:\n",
    "    data[\"processed_text\"] = data[\"text\"].apply(preprocess_text)\n",
    "except Exception as e:\n",
    "    print(f\"Error procesando texto: {e}\")\n",
    "    raise\n",
    "\n",
    "# Tarea 2 de NLP: Tokenización para modelo de Deep Learning\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(data[\"processed_text\"])\n",
    "\n",
    "sequences = tokenizer.texts_to_sequences(data[\"processed_text\"])\n",
    "word_index = tokenizer.word_index\n",
    "\n",
    "# Padding de las secuencias\n",
    "max_length = max(len(seq) for seq in sequences)\n",
    "data_padded = pad_sequences(sequences, maxlen=max_length)\n",
    "\n",
    "# Dividir los datos en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(data_padded, data[\"label\"], test_size=0.2, random_state=42)\n",
    "\n",
    "# Construir la red neuronal simple\n",
    "model = Sequential([\n",
    "    Embedding(input_dim=len(word_index) + 1, output_dim=64, input_length=max_length),\n",
    "    LSTM(64, return_sequences=False),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Entrenar la red neuronal\n",
    "model.fit(X_train, y_train, epochs=5, batch_size=32, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluar el modelo\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f\"Pérdida: {loss}, Precisión: {accuracy}\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
